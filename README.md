# immobilien-email-scraper

## ğŸ“§ 11880.com E-Mail-Scraper fÃ¼r Hausverwaltungen

Ein Python-basierter Web-Scraper, der automatisiert E-Mail-Adressen von Hausverwaltungen in DÃ¼sseldorf von der Website 11880.com sammelt.

## ğŸš€ Features

- **Automatische Navigation** auf 11880.com
- **Intelligente E-Mail-Extraktion** mit mehreren Fallback-Strategien
- **Robuste Fehlerbehandlung** und Retry-Mechanismen  
- **CSV-Export** mit Zeitstempel und Duplikatsvermeidung
- **Ethisches Scraping** mit angemessenen Delays
- **Modulare Architektur** fÃ¼r einfache Erweiterungen

## ğŸ› ï¸ Installation

### 1. Repository klonen
```bash
git clone <repository-url>
cd immobilien-email-scraper
```

### 2. Virtual Environment erstellen
```bash
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# oder
venv\Scripts\activate     # Windows
```

### 3. Dependencies installieren
```bash
pip install -r requirements.txt
```

### 4. Playwright Browser installieren
```bash
playwright install chromium
```

## âš™ï¸ Konfiguration

Die Konfiguration erfolgt Ã¼ber `config/settings.yaml`:

```yaml
target:
  search_term: "Hausverwaltungen"
  location: "DÃ¼sseldorf"
  
scraping:
  delay_between_requests:
    min: 2
    max: 5
  max_pages: 50
```

## ğŸ¯ Verwendung

### Basis-Scraping
```bash
python main.py
```

### Mit benutzerdefinierten Parametern
```bash
python main.py --location "KÃ¶ln" --search-term "Immobilienmakler"
```

## ğŸ“Š Output

Der Scraper erstellt CSV-Dateien mit folgenden Spalten:
- **Firma**: Name der Hausverwaltung
- **Adresse**: VollstÃ¤ndige Adresse  
- **Website**: URL der Firmen-Website (falls verfÃ¼gbar)
- **E-Mail**: Extrahierte E-Mail-Adresse

Beispiel: `data/hausverwaltungen_duesseldorf_2024-01-15_14-30-25.csv`

## ğŸ”§ Projektstruktur

```
immobilien-email-scraper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper/          # Hauptkomponenten des Scrapers
â”‚   â”œâ”€â”€ utils/            # Hilfsfunktionen
â”‚   â””â”€â”€ export/           # Datenexport-Module
â”œâ”€â”€ config/               # Konfigurationsdateien
â”œâ”€â”€ logs/                 # Log-Dateien
â”œâ”€â”€ data/                 # Ausgabe-Dateien
â”œâ”€â”€ tests/                # Unit Tests
â””â”€â”€ requirements.txt      # Python Dependencies
```

## ğŸ¤– Technologie-Stack

- **Python 3.8+**
- **Playwright** - Browser-Automatisierung
- **Pandas** - Datenverarbeitung
- **BeautifulSoup4** - HTML-Parsing
- **PyYAML** - Konfiguration
- **Asyncio** - Asynchrone Verarbeitung

## ğŸ›¡ï¸ Ethisches Scraping

Dieser Scraper befolgt Best Practices:
- âœ… Respektiert `robots.txt`
- âœ… Verwendet angemessene Delays zwischen Requests
- âœ… Implementiert Retry-Mechanismen mit Exponential Backoff
- âœ… Sammelt nur Ã¶ffentlich verfÃ¼gbare Daten
- âœ… Vermeidet Ãœberlastung der Ziel-Website

## ğŸ“ Logging

Alle AktivitÃ¤ten werden geloggt:
- Erfolgreiche Extraktionen
- Fehlgeschlagene Requests
- Performance-Metriken
- Fehlerdetails fÃ¼r Debugging

## ğŸ§ª Testing

```bash
pytest tests/
```

## ğŸ“„ Lizenz

Dieses Projekt steht unter der MIT-Lizenz. Siehe [LICENSE](LICENSE) fÃ¼r Details.

## âš ï¸ Rechtlicher Hinweis

Dieses Tool dient ausschlieÃŸlich zu Bildungszwecken. Stellen Sie sicher, dass Sie alle geltenden Gesetze und Nutzungsbedingungen einhalten, bevor Sie es verwenden.

## ğŸ¤ Beitragen

Contributions sind willkommen! Bitte erstellen Sie einen Pull Request oder Ã¶ffnen Sie ein Issue.

---

**Erstellt mit â¤ï¸ fÃ¼r die Immobilienbranche**
